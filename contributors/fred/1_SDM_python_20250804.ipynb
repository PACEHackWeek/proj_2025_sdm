{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced716b5",
   "metadata": {},
   "source": [
    "# Species Distribution Modeling with Occurrence Data\n",
    "\n",
    "<img src=\"https://oceanhackweek.org/assets/img/ohw-logo.png\" width=\"200\" align=\"right\">\n",
    "\n",
    "This notebook follows the [Ocean HackWeek tutorial](https://oceanhackweek.org/tutorials_marine_sdm/tutorial/Steps_occurences.html) on Species Distribution Modeling (SDM) using occurrence data.\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Obtain and clean species occurrence data\n",
    "2. Acquire and process environmental raster data\n",
    "3. Prepare data for SDM modeling\n",
    "4. Build and evaluate a species distribution model\n",
    "5. Visualize habitat suitability predictions\n",
    "\n",
    "**Species:** Blue Shark (*Prionace glauca*)  \n",
    "**Region:** North Atlantic Ocean  \n",
    "**Environmental Variables:** Bathymetry and Sea Surface Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c27df0",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de71381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "#!pip install pandas geopandas rasterio matplotlib scikit-learn contextily numpy seaborn pyimpute mapclassify\n",
    "#pip install robis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a205bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import contextily as ctx\n",
    "from pyimpute import load_training_vector, load_targets, impute\n",
    "import tempfile\n",
    "from shapely.geometry import Point, box\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef41a9",
   "metadata": {},
   "source": [
    "## 2. Obtain and Prepare Occurrence Data\n",
    "\n",
    "We'll use occurrence records for Blue Shark from GBIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa97659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download occurrence data\n",
    "occ_url = \"https://raw.githubusercontent.com/OceanHackWeek/ohw-tutorials/main/marine_sdm/data/species_data.csv\"\n",
    "occ_path = \"blue_shark_occurrences.csv\"\n",
    "\n",
    "# Download if not already present\n",
    "if not os.path.exists(occ_path):\n",
    "    !wget -O {occ_path} {occ_url}\n",
    "\n",
    "# Load data\n",
    "occurrences = pd.read_csv(occ_path)\n",
    "print(f\"Loaded {len(occurrences)} occurrence records\")\n",
    "\n",
    "# Show data structure\n",
    "occurrences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef8eb1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Basic cleaning\n",
    "print(\"Cleaning occurrence data...\")\n",
    "original_count = len(occurrences)\n",
    "\n",
    "# 1. Remove records without coordinates\n",
    "occurrences = occurrences.dropna(subset=['decimalLongitude', 'decimalLatitude'])\n",
    "\n",
    "# 2. Remove records with 0,0 coordinates\n",
    "occurrences = occurrences[(occurrences.decimalLongitude != 0) | (occurrences.decimalLatitude != 0)]\n",
    "\n",
    "# 3. Remove duplicate coordinates\n",
    "occurrences = occurrences.drop_duplicates(subset=['decimalLongitude', 'decimalLatitude'])\n",
    "\n",
    "# 4. Filter to study area (North Atlantic)\n",
    "study_area = box(-100, 0, 0, 70)  # Approximate North Atlantic bounds\n",
    "geometry = [Point(xy) for xy in zip(occurrences.decimalLongitude, occurrences.decimalLatitude)]\n",
    "gdf_occurrences = gpd.GeoDataFrame(occurrences, geometry=geometry, crs=\"EPSG:4326\")\n",
    "gdf_occurrences = gdf_occurrences[gdf_occurrences.within(study_area)]\n",
    "\n",
    "print(f\"Retained {len(gdf_occurrences)} of {original_count} records after cleaning\")\n",
    "\n",
    "# Visualize occurrences\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "gdf_occurrences.plot(ax=ax, color='red', markersize=8, alpha=0.7, label='Occurrence')\n",
    "ctx.add_basemap(ax, crs=gdf_occurrences.crs.to_string(), source=ctx.providers.Esri.OceanBasemap)\n",
    "ax.set_title(\"Blue Shark Occurrence Records in North Atlantic\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed533b9",
   "metadata": {},
   "source": [
    "## 3. Acquire Environmental Data\n",
    "\n",
    "We'll use bathymetry and sea surface temperature (SST) rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721f048",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def download_raster(url, filename):\n",
    "    \"\"\"Download a raster file if not already present\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        !wget -O {filename} {url}\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76836d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download bathymetry data\n",
    "bathy_url = \"https://github.com/OceanHackWeek/ohw-tutorials/raw/main/marine_sdm/data/bathymetry.tif\"\n",
    "bathy_path = download_raster(bathy_url, \"bathymetry.tif\")\n",
    "\n",
    "# Download sea surface temperature data\n",
    "sst_url = \"https://github.com/OceanHackWeek/ohw-tutorials/raw/main/marine_sdm/data/sst.tif\"\n",
    "sst_path = download_raster(sst_url, \"sst.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460973",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Visualize environmental rasters\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bathymetry\n",
    "with rasterio.open(bathy_path) as src:\n",
    "    bathy = src.read(1)\n",
    "    show(src, ax=ax1, title='Bathymetry (m)', cmap='Blues_r')\n",
    "    ax1.set_xlabel(\"Longitude\")\n",
    "    ax1.set_ylabel(\"Latitude\")\n",
    "\n",
    "# Sea Surface Temperature\n",
    "with rasterio.open(sst_path) as src:\n",
    "    sst = src.read(1)\n",
    "    show(src, ax=ax2, title='Sea Surface Temperature (Â°C)', cmap='plasma')\n",
    "    ax2.set_xlabel(\"Longitude\")\n",
    "    ax2.set_ylabel(\"Latitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48170710",
   "metadata": {},
   "source": [
    "## 4. Data Processing\n",
    "\n",
    "We'll extract environmental values at occurrence points and generate background points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c83cf9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_raster_values(gdf, raster_path, band=1, nodata=np.nan):\n",
    "    \"\"\"Extract raster values at point locations\"\"\"\n",
    "    values = []\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        for point in gdf.geometry:\n",
    "            x, y = point.x, point.y\n",
    "            if src.bounds.left <= x <= src.bounds.right and src.bounds.bottom <= y <= src.bounds.top:\n",
    "                row, col = src.index(x, y)\n",
    "                window = ((row, row+1), (col, col+1))\n",
    "                data = src.read(band, window=window)\n",
    "                if data.size > 0 and data[0, 0] != src.nodata:\n",
    "                    values.append(data[0, 0])\n",
    "                else:\n",
    "                    values.append(nodata)\n",
    "            else:\n",
    "                values.append(nodata)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade97f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting environmental values at occurrence points...\")\n",
    "gdf_occurrences['bathy'] = extract_raster_values(gdf_occurrences, bathy_path)\n",
    "gdf_occurrences['sst'] = extract_raster_values(gdf_occurrences, sst_path)\n",
    "\n",
    "# Remove points with missing environmental data\n",
    "original_occ_count = len(gdf_occurrences)\n",
    "gdf_occurrences = gdf_occurrences.dropna(subset=['bathy', 'sst'])\n",
    "print(f\"Retained {len(gdf_occurrences)} of {original_occ_count} occurrence points with valid environmental data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating background points...\")\n",
    "minx, miny, maxx, maxy = gdf_occurrences.total_bounds\n",
    "n_background = len(gdf_occurrences) * 10  # 10:1 background-to-presence ratio\n",
    "\n",
    "# Create random points within bounds\n",
    "background_points = gpd.GeoDataFrame(\n",
    "    geometry=[Point(x, y) for x, y in zip(\n",
    "        np.random.uniform(minx, maxx, n_background),\n",
    "        np.random.uniform(miny, maxy, n_background)\n",
    "    )],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Extract environmental data for background points\n",
    "background_points['bathy'] = extract_raster_values(background_points, bathy_path)\n",
    "background_points['sst'] = extract_raster_values(background_points, sst_path)\n",
    "background_points['presence'] = 0\n",
    "\n",
    "# Clean background points\n",
    "original_bg_count = len(background_points)\n",
    "background_points = background_points.dropna(subset=['bathy', 'sst'])\n",
    "print(f\"Retained {len(background_points)} of {original_bg_count} background points with valid environmental data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "gdf_occurrences['presence'] = 1\n",
    "combined = pd.concat([\n",
    "    gdf_occurrences[['presence', 'bathy', 'sst', 'geometry']],\n",
    "    background_points[['presence', 'bathy', 'sst', 'geometry']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Visualize environmental space\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x='bathy', \n",
    "    y='sst', \n",
    "    hue='presence', \n",
    "    data=combined, \n",
    "    palette={0: 'blue', 1: 'red'}, \n",
    "    alpha=0.3\n",
    ")\n",
    "plt.title(\"Environmental Space: Presence vs Background\")\n",
    "plt.xlabel(\"Bathymetry (m)\")\n",
    "plt.ylabel(\"Sea Surface Temperature (Â°C)\")\n",
    "plt.legend(title=\"Presence\", labels=['Background', 'Blue Shark'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d4586",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "We'll train a Random Forest classifier to predict species occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = combined[['bathy', 'sst']]\n",
    "y = combined['presence']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)} ({len(y_train[y_train==1])} presence)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(y_test[y_test==1])} presence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceea086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"Training Random Forest model...\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=10, \n",
    "    random_state=42, \n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f\"Training accuracy: {train_score:.4f}\")\n",
    "print(f\"Testing accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0b0c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Calculate AUC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Model AUC: {auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Background', 'Presence'],\n",
    "            yticklabels=['Background', 'Presence'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances, palette='viridis')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0763693a",
   "metadata": {},
   "source": [
    "## 6. Habitat Suitability Mapping\n",
    "\n",
    "Predict habitat suitability across the entire study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769a5eb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create a function for raster prediction\n",
    "def predict_raster(model, raster_paths, output_path, nodata=-9999):\n",
    "    \"\"\"Predict habitat suitability across raster layers\"\"\"\n",
    "    # Load target rasters\n",
    "    raster_stack = []\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        profile = src.profile\n",
    "        transform = src.transform\n",
    "        height, width = src.shape\n",
    "        raster_stack.append(src.read(1))\n",
    "    \n",
    "    for path in raster_paths[1:]:\n",
    "        with rasterio.open(path) as src:\n",
    "            raster_stack.append(src.read(1))\n",
    "    \n",
    "    # Stack rasters into a 3D array\n",
    "    stacked = np.dstack(raster_stack)\n",
    "    original_shape = stacked.shape[:2]\n",
    "    stacked = stacked.reshape(-1, stacked.shape[2])\n",
    "    \n",
    "    # Predict\n",
    "    print(\"Predicting habitat suitability...\")\n",
    "    suitability = model.predict_proba(stacked)[:, 1]\n",
    "    suitability = suitability.reshape(original_shape)\n",
    "    \n",
    "    # Set nodata values\n",
    "    mask = np.isnan(stacked[:, 0]) | (stacked[:, 0] == nodata)\n",
    "    suitability.flat[mask] = nodata\n",
    "    \n",
    "    # Save output\n",
    "    profile.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        nodata=nodata,\n",
    "        compress='lzw'\n",
    "    )\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(suitability.astype(rasterio.float32), 1)\n",
    "    \n",
    "    return suitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853af299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict habitat suitability\n",
    "suitability_path = \"habitat_suitability.tif\"\n",
    "suitability = predict_raster(model, [bathy_path, sst_path], suitability_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05669b41",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Visualize habitat suitability\n",
    "with rasterio.open(suitability_path) as src:\n",
    "    suitability = src.read(1)\n",
    "    profile = src.profile\n",
    "    \n",
    "    # Create a custom colormap\n",
    "    cmap = plt.cm.viridis\n",
    "    cmap.set_bad('lightgrey', 1.0)  # Color for nodata\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    im = plt.imshow(suitability, cmap=cmap, \n",
    "                   vmin=0, vmax=1, \n",
    "                   extent=[src.bounds.left, src.bounds.right, \n",
    "                           src.bounds.bottom, src.bounds.top])\n",
    "    \n",
    "    # Add occurrence points\n",
    "    gdf_occurrences.plot(ax=plt.gca(), color='red', markersize=5, alpha=0.7)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, fraction=0.025, pad=0.04)\n",
    "    cbar.set_label('Habitat Suitability Probability')\n",
    "    \n",
    "    plt.title(\"Blue Shark Habitat Suitability in North Atlantic\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1f30b",
   "metadata": {},
   "source": [
    "## 7. Model Interpretation\n",
    "\n",
    "Analyze the response curves to understand how environmental variables affect habitat suitability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26edf0c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create response curves\n",
    "def plot_response_curve(model, feature_name, feature_range, ax, other_feature_value=0):\n",
    "    \"\"\"Plot response curve for a given feature\"\"\"\n",
    "    # Create synthetic data\n",
    "    synthetic = np.zeros((len(feature_range), 2))\n",
    "    synthetic[:, 0] = other_feature_value  # Hold other feature constant\n",
    "    synthetic[:, 1] = feature_range\n",
    "    \n",
    "    # Swap columns based on feature position\n",
    "    if feature_name == 'bathy':\n",
    "        synthetic = synthetic[:, [0, 1]]\n",
    "    else:\n",
    "        synthetic = synthetic[:, [1, 0]]\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict_proba(synthetic)[:, 1]\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(feature_range, predictions, linewidth=2)\n",
    "    ax.set_title(f\"Response Curve: {feature_name}\")\n",
    "    ax.set_xlabel(feature_name)\n",
    "    ax.set_ylabel(\"Probability of Occurrence\")\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15311461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate response curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bathymetry response curve\n",
    "bathy_range = np.linspace(\n",
    "    combined['bathy'].min(), \n",
    "    combined['bathy'].max(), \n",
    "    100\n",
    ")\n",
    "plot_response_curve(model, 'bathy', bathy_range, ax1, \n",
    "                    other_feature_value=combined['sst'].median())\n",
    "\n",
    "# SST response curve\n",
    "sst_range = np.linspace(\n",
    "    combined['sst'].min(), \n",
    "    combined['sst'].max(), \n",
    "    100\n",
    ")\n",
    "plot_response_curve(model, 'sst', sst_range, ax2, \n",
    "                    other_feature_value=combined['bathy'].median())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a409302",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated a complete workflow for marine species distribution modeling:\n",
    "1. Obtained and cleaned occurrence data for Blue Shark\n",
    "2. Acquired and processed environmental raster data (bathymetry and SST)\n",
    "3. Prepared data for modeling by extracting environmental values and generating background points\n",
    "4. Trained and evaluated a Random Forest model\n",
    "5. Predicted and visualized habitat suitability across the study area\n",
    "6. Interpreted model results using response curves\n",
    "\n",
    "The model achieved an AUC of {auc:.3f}, indicating good predictive performance. The habitat suitability map shows that Blue Sharks prefer deeper, warmer waters in the North Atlantic."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
